## 模型实战(三)--Albert究竟能不能上线？能！效果怎么样？很好！耗时如何？20ms！！

Bert简单粗暴效果好，估计很多同学一直在想上线，奈何Bert推理实在是慢。所以针对Bert的加速就是一个很值得做的领域，出来的方法也很多，比如做模型的压缩，蒸馏，或者训练的时候的小技巧（最近有个fastbert做文本分类，原作者已经开源了，效果不错，大家可以试试，大概内容就是在Bert-12层里，简单的数据提前出来，复杂数据走完全程，很好的idea）

Albert是其中之一。之前看过一篇文章，讲的是关于Albert如何在上线使用。我做了个简单的笔记，希望对大家有帮助，阅读的文章是《ALBERT在房产领域的实践》链接在最后。

接下来分为两个部分，第一部分是整体概括，时间不够的朋友看完第一部分把握住重点即可，感兴趣的可以继续看第二部分的详细介绍。

#### 1. 简单介绍：

因为之前线下试过ALbert的效果，和Bert比，效果掉的有点多，而且推理速度和Bert比较没有那么明显的快。但是贝壳找房将Albert用在意图识别上，而且上线了，于是精读了一下这个文章。

贝壳找房，使用Albert_Tiny（大小4M），基于30G房产领域进一步训练，训练耗时42小时，上线意图识别任务，测评效果提升8个点，响应时间为20ms。
（简直太精炼了！！文中还有一个有意思的点是贝壳找房的意图识别的架构，是分级，具体的看下面吧）

#### 2.详细介绍

##### 2.1模型的选择

贝壳找房使用的是 Albert_Tiny 模型。对于 Albert_Tiny，结构是4层Encoder (原文说的是4个Transformer，不太准确)。

其实对于 Albert，原理就不多说了，注意它最主要模型大小减少最主要的原因是共享参数的存在，所以在推理的时候，优势并不明显。贝壳找房这里使用的是4层encoder，其实
推理速度变快主要是因为这个，层数减少了，推理速度就变快了。

##### 2.2模型训练

模型训练常规来说是两个步骤，第一步获取作者原始的模型，第二步使用自己的任务数据进行微调。没条件的同学做这两个步骤就可以了，贝壳找房为了提高模型的准确度，使用内部的房产数据，基于作者的原始数据，又进一步训练。

> 房产领域中的文本语料特点突出，具有很多房产领域特有的语言习惯和专业词汇，因此利用房产领域的文本进行进一步的领域预训练十分必要

数据情况是这样的：

> 30G左右的房产领域语料; train_batch_size=512;
>
> max_seq_length=128; num_train_steps=30000;
>
> 4块v100; 训练了42h

接下来，是微调，贝壳找房做了两个任务的微调（一个是意图识别，一个是句式判定），线下效果都不错，我这里只说他们上线的那个意图识别的任务。

##### 2.3 意图识别架构-很有意思

使用Albert做意图识别没什么特殊的，直接train就可以。这里我想提一个比较有意思的点，就是贝壳找房的意图识别的框架。

想象这样一个场景，你手里有10000个意图，你要对接口传过来的一句话进行意图识别，判断一下他是想要娱乐/电影/公益...（我随意写的意图，不太清楚房产领域，就拿我熟悉的分类情况举例吧）。

从word2vec我们就可以知道，最后一层的softmax在类别数据较多的时候计算量是很大的。

如果是你，你怎么优化？你当然可以使用霍夫曼进行简化，这也是为啥贝壳找房最初使用的是fasttext作baseline。

但是！！这样的场景还会存在一个特别大的问题，就是如果，因为业务改版，原来的10000个意图，增大或者减少了几百个意图，你这个模型怎么办？

如果你只是训练了一个10000分类的多分类模型，毫无疑问，你的这个模型在改版之后就废了，基本没啥用。

基于此，还能怎么优化？

有这么一种做法，对每个意图进行两两分类，是不是找娱乐领域，是不是电影领域，是不是公益领域等等，这样，在出现意图增加或者减少的时候，废除的模型就是相关的那么几个，你大部分意图模型还是可以用的。而且对每个意图的优化可以并行着做。

但是上面这个还存在一个问题，就是模型数量太多了，维护起来不太好维护。所以贝壳这个架构就很有意思。

它先使用一个模型（12个技能多分类）粗分类了一遍，然后再针对每个技能结果做一个多分类。举一个熟悉的例子，一个文本过来，我先给他分为娱乐领域，再判断是娱乐领域下的哪个子标签，是关于娱乐明星的，还是关于电视剧的，还是关于娱乐八卦的。

用一个简单的话说，就是做了个二级标签，这个方法很多垂直领域网站都有用到，贝壳把这个方法扩展到意图识别，想法很简单，不过效果很好。

> 贝壳找房的意图识别的架构，定义了256个意图，由于意图种类过多，难以使用一个模型进行分类表示，所以我们又将256类意图进行向上归类，定义了13个技能类别（包含一个other类别），每个技能下对应着一部分意图。在预测过程中，query先经过技能模型，得到技能的标签，然后根据技能标签决定调取哪个意图模型。所以，我们一共有1个技能模型和12个意图模型，

#### 2.4 意图识别效果

线下：fasttext 0.75
原始albert+微调 0.80
原始albert+领域训练+微调 0.83



##### 2.5 意图识别上线

上线注意两个点。

第一个是数据预处理和原作者训练albert的保持一致，这个和word2vec很相似，类似使用相同的分词器。

第二个就是控制响应时间，albert的响应时间大概在20ms到30ms之间，完全符合上线要求。



在这里说一下，就是猜测一下为啥Albert为啥只是用在了贝壳找房的意图识别这个任务上。我自己线下测试的时候，Albert的效果在文本分类和文本相似度判定这种简单任务上效果相比Bert能掉2 到3个点，至于其他复杂任务，更惨。

所以总结来说，Albert还是在这种简单任务更适合，速度更快，效果也还行。

打完收工，关注一波公众号吧！！有很多别的内容！！

微信公众号：NLP从入门到放弃

![微信公众号](../images/wechat.png)

全文参考链接：
[ALBERT在房产领域的实践](https://flashgene.com/archives/117297.html)

