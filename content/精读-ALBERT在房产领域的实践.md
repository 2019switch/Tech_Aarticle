## 模型实战(三)--Albert究竟能不能上线？能！效果怎么样？很好！耗时如何？20ms！！

Bert 简单粗暴效果好，估计很多同学一直在想上线，奈何Bert 推理实在是慢。

所以针对 Bert 的加速就是一个很值得做的领域，出来的方法也很多。比如做模型的压缩，蒸馏，或者训练的时候的小技巧。

最近有个  <font color=SaddleBrown>Fastbert</font> 做文本分类，原作者已经开源了，效果不错，大家可以试试。大概内容就是针对 <font color=SaddleBrown>Bert-12/24</font>，简单的数据提前输出结果，复杂数据走完全程，是一个很好的idea。

书归正传，这个文章是之前看过一篇文章，讲的是关于 Albert 如何在上线做<font color=SaddleBrown>意图识别</font>。我做了个简单的笔记，希望对大家有帮助，阅读的文章是《ALBERT在房产领域的实践》链接在最后。

接下来分为两个部分，第一部分是整体概括，时间不够的朋友看完第一部分把握住重点即可，感兴趣的可以继续看第二部分的详细介绍。

******

### 1. 简单介绍：

<font color=SaddleBrown>贝壳找房，使用Albert_Tiny（大小4M），基于30G房产领域进一步训练，训练耗时42小时，上线意图识别任务，测评效果提升8个点，响应时间为20ms。</font>

简直太精炼了！！文中还有一个有意思的点是贝壳找房的意图识别的架构，是分级架构，具体的看下面吧

### 2. 详细介绍

我先说一下自己的经验，之前线下测试过 ALbert 的效果，和 Bert 比，效果掉的有点多，而且推理速度和 Bert 相比并不是特别的有优势。所以我们来看一下贝壳找房为了模型上线做了哪些努力。

*******

#### 2.1模型的选择

贝壳找房使用的是 <font color=SaddleBrown>Albert_Tiny </font>模型。对于 Albert_Tiny，结构是 4 层 Encoder。

注解：原文说的是 4 个 Transformer，不太准确。

其实对于 Albert ，原理就不多说了，注意它有个细节点：模型大小减少最主要的原因是共享参数的存在。所以在推理的时候，速度优势并不明显，该做的推理并没有减少多少。

为了解决这个问题，贝壳找房这里使用的是 4 层 encoder，其实推理速度变快主要是因为这个，层数减少了，推理速度就变快了。

*******

#### 2.2模型训练

对于 Bert 系列的模型来说，训练常规来说是两个步骤。

第一步获取作者原始的模型，一般来说谷歌这种大佬公司都会放出来各种语言的预训练模型。

第二步使用自己的任务数据进行微调。没条件的同学做这两个步骤就可以了。贝壳找房为了提高模型的准确度，使用内部的房产数据，基于作者的原始数据，又进一步训练。

数据情况是这样的：

- <font color= RoyalBlue>30G左右的房产领域语料;</font>
- <font color= RoyalBlue>train_batch_size=512;</font>
-  <font color= RoyalBlue>max_seq_length=128;</font>
- <font color= RoyalBlue>num_train_steps=30000;</font>
- <font color= RoyalBlue>4块v100; 训练了42h</font>

接下来，是对模型做微调。贝壳找房做了两个任务的微调，一个是意图识别，一个是句式判定，线下效果都不错，我这里谈一下上线的意图识别的任务。

##### 2.3 意图识别架构-很有意思

使用 Albert 做意图识别没什么特殊的，就是一个分类问题。这里我想提一个比较有意思的点，就是贝壳找房的

<font color=SaddleBrown>意图识别的框架</font>。

想象这样一个场景，你手里有 10000 个意图，你要对接口传过来的一句话进行意图识别。判断一下他是想要：娱乐/电影/公益...

这是我随意写的类别，不太清楚房产领域，就拿我熟悉的分类情况举例吧。

从 <font color=SaddleBrown>Word2vec</font>  我们就可以知道，最后一层的 softmax 在类别数据较多的时候计算量是很大的。

如果是你，你怎么优化？你当然可以使用霍夫曼进行简化，这也是为啥贝壳找房最初使用的是 Fasttext 作 Baseline 。

但是！！这样的场景还会存在一个特别大的问题，就是如果，因为业务改版，原来的 10000 个意图，增大或者减少了几百个意图，你这个模型怎么办？

如果你只是训练了一个 10000 分类的多分类模型，毫无疑问，你的这个模型在改版之后就废了，基本没啥用。

基于此，还能怎么优化？

有这么一种做法，对每个意图进行两两分类，是不是找娱乐领域，是不是电影领域，是不是公益领域等等。

这样，在出现意图增加或者减少的时候，废除的模型就是相关的那么几个，你大部分意图模型还是可以用的。而且对每个意图的优化可以并行着做。

但是上面这个还存在一个问题，就是模型数量太多了，维护起来不太好维护。所以贝壳这个架构就很有意思。

它先使用一个模型，做一个12个技能的多分类，相当于首先做了一个粗分类。然后再针对每个技能结果做一个多分类。

举一个简单的例子帮助理解，一个文本从接口传过来过来，我先给他分为娱乐领域（这一个步骤相当于技能分类-粗分类），再判断是娱乐领域下的哪个子标签（相当于再分类），是关于娱乐明星的，还是关于电视剧的，还是关于娱乐八卦的。

用一个简单的话说，就是做了个二级标签，这个方法很多垂直领域网站都有用到，贝壳把这个方法扩展到意图识别，想法很简单，不过效果很好。

******

#### 2.4 意图识别效果

- <font color= RoyalBlue>Baseline：fasttext 0.75</font>
- <font color= RoyalBlue>原始albert+微调 0.80</font>
- <font color= RoyalBlue>原始albert+领域训练+微调 0.83</font>

******

#### 2.5 意图识别上线

上线注意两个点。

第一个是数据预处理和原作者训练 Albert 的保持一致，这个和 Word2vec 很相似，类似使用相同的分词器。

第二个就是控制响应时间，Albert的响应时间大概在 20ms 到 30ms 之间，完全符合上线要求。



### 3. 简单总结

没啥好说的了，只是想在这里猜测一下为啥 Albert 只是用在了贝壳找房的意图识别这个任务上（当然也有可能是用在了别的任务但是没说出来）。我自己线下测试的时候，Albert 的效果在文本分类和文本相似度判定这种简单任务上效果相比 Bert 能掉2 到3个点，至于其他复杂任务，更惨。

所以总结来说，Albert还是在这种简单任务更适合，速度能接受，效果也还行。

打完收工，关注一波公众号吧！！有很多别的内容！！

微信公众号：NLP从入门到放弃

![微信公众号](../images/wechat.png)

全文参考链接：
[ALBERT在房产领域的实践](
